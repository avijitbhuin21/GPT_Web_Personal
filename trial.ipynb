{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tse4.mm.bing.net/th/id/OIG.8p7qqYsJLUNns4fGiPc6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://tse4.mm.bing.net/th/id/OIG.8p7qqYsJLUNns4fGiPc6\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tse3.mm.bing.net/th/id/OIG.e32nLE4CeSg6NYMJL3tG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://tse3.mm.bing.net/th/id/OIG.e32nLE4CeSg6NYMJL3tG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tse2.mm.bing.net/th/id/OIG.nwp2HCXACsASxBRjLTCb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://tse2.mm.bing.net/th/id/OIG.nwp2HCXACsASxBRjLTCb\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tse1.mm.bing.net/th/id/OIG.Eg.ayWoylqMyyHB5q20d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://tse1.mm.bing.net/th/id/OIG.Eg.ayWoylqMyyHB5q20d\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bing_Image_generator import ImageGen\n",
    "from IPython.display import Image,display\n",
    "\n",
    "auth_cookie = \"1glHV2CTJBuTvq2UOoJIWLB6F-ciBOvMFhRX2FNuDybkqaFPfqZofkh9FanSF1z2vBujStWGLXbWRMagfukBkoRMOUdoNEgtkVqOoTYSp_cE3RrooY754f-aYqJOy16W7C3f8yIYuaNMSdsajPmOxUkGFsGkXkXF8tIEE8yfjOjk-y-HGUbcgn-arQHONGdkZtWrkgtHr0xyVLEH6ymkSveFF9x3lM7i1jgoJk1QdJIE\"\n",
    "auth_cookie_SRCHHPGUSR = \"HV=1692014599&CW=1646&CH=793&SCW=1628&SCH=1991&BRW=XW&BRH=M&SRCHLANG=en&DM=1&THEME=1&PRVCW=1646&PRVCH=793&DPR=1.1&UTC=330&PV=15.0.0&EXLTT=31&cdxtone=Precise&cdxtoneopts=h3precise,clgalileo,gencontentv3&IG=4B70037EE7AC4BBCB29F7851CEA39E82&CMUID=23622FAE0541681D20E73C8804DA6996&VCW=1628&VCH=793&WEBTHEME=1\"\n",
    "image_generator = ImageGen(auth_cookie, auth_cookie_SRCHHPGUSR)\n",
    "\n",
    "prompt = \"An artistic masterpiece of a guiter made of white flowers on a green background with cinematic lighting.\"\n",
    "image_links = image_generator.get_images(prompt)\n",
    "\n",
    "for link in image_links:\n",
    "    print(link)\n",
    "    display(Image(url=link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-MYDRRY4IIy5Yw4L4Sf6vt85A/user-SDsOwr5gZbfeaO5oMmt3K1Qw/img-zOP8uI0V29Iae3hC4SioyA3a.png?st=2023-08-22T15%3A59%3A37Z&se=2023-08-22T17%3A59%3A37Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-08-21T20%3A06%3A28Z&ske=2023-08-22T20%3A06%3A28Z&sks=b&skv=2021-08-06&sig=yDGN4ccVuiZoLT2TqabYzOR6kOSQQTGwwI3cnrZ7og0%3D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-MYDRRY4IIy5Yw4L4Sf6vt85A/user-SDsOwr5gZbfeaO5oMmt3K1Qw/img-zOP8uI0V29Iae3hC4SioyA3a.png?st=2023-08-22T15%3A59%3A37Z&se=2023-08-22T17%3A59%3A37Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-08-21T20%3A06%3A28Z&ske=2023-08-22T20%3A06%3A28Z&sks=b&skv=2021-08-06&sig=yDGN4ccVuiZoLT2TqabYzOR6kOSQQTGwwI3cnrZ7og0%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-MYDRRY4IIy5Yw4L4Sf6vt85A/user-SDsOwr5gZbfeaO5oMmt3K1Qw/img-IRP6FrxkGrtRsl8SMoHQW4rS.png?st=2023-08-22T15%3A59%3A37Z&se=2023-08-22T17%3A59%3A37Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-08-21T20%3A06%3A28Z&ske=2023-08-22T20%3A06%3A28Z&sks=b&skv=2021-08-06&sig=62xe/Q8pA/t4HfleYelO7Qwn9W9gTW9dXyhcwz42hEc%3D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-MYDRRY4IIy5Yw4L4Sf6vt85A/user-SDsOwr5gZbfeaO5oMmt3K1Qw/img-IRP6FrxkGrtRsl8SMoHQW4rS.png?st=2023-08-22T15%3A59%3A37Z&se=2023-08-22T17%3A59%3A37Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-08-21T20%3A06%3A28Z&ske=2023-08-22T20%3A06%3A28Z&sks=b&skv=2021-08-06&sig=62xe/Q8pA/t4HfleYelO7Qwn9W9gTW9dXyhcwz42hEc%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "from IPython.display import Image,display\n",
    "\n",
    "openai.api_key=\"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\"\n",
    "\n",
    "response = openai.Image.create(\n",
    "  prompt=\"An artistic masterpiece of a guiter made of white flowers on a green background with cinematic lighting.\",\n",
    "  size=\"1024x1024\",\n",
    "  n=2\n",
    ")\n",
    "image_url =[]\n",
    "for i in response['data']:\n",
    "    image_url.append(i['url'])\n",
    "    \n",
    "for link in image_url:\n",
    "    print(link)\n",
    "    display(Image(url=link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPT-3.5:\n",
      "Once upon a time, in the heart of the African savannah, there lived a gentle and wise elephant named Kibo. Kibo was known for his enormous size and his kind heart. He roamed freely with his herd, always leading them to the best watering holes and the lushest grazing lands.\n",
      "\n",
      "One day, as Kibo and his herd were peacefully enjoying their afternoon meal, they heard a distress call coming from a nearby village. Curious, Kibo decided to investigate. He arrived to find the villagers in a state of panic, as their only well had dried up, leaving them without water.\n",
      "\n",
      "Moved by their plight, Kibo knew he had to help. With his powerful trunk, he dug deep into the ground, unearthing a hidden underground spring. Water gushed forth, quenching the villagers' thirst and bringing hope back to their lives.\n",
      "\n",
      "News of Kibo's incredible act of kindness spread far and wide. People from distant lands came to witness the miracle elephant who had saved a village. Kibo became a symbol of hope and compassion, inspiring others to lend a helping hand to those in need.\n",
      "\n",
      "From that day forward, Kibo continued to use his strength and wisdom to assist others. He became a beloved figure, known as the Guardian of the Savannah. And whenever someone faced a challenge, they would look to the horizon, hoping to catch a glimpse of Kibo, the mighty elephant who taught the world the power of kindness."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Once upon a time, in the heart of the African savannah, there lived a gentle and wise elephant named Kibo. Kibo was known for his enormous size and his kind heart. He roamed freely with his herd, always leading them to the best watering holes and the lushest grazing lands.\\n\\nOne day, as Kibo and his herd were peacefully enjoying their afternoon meal, they heard a distress call coming from a nearby village. Curious, Kibo decided to investigate. He arrived to find the villagers in a state of panic, as their only well had dried up, leaving them without water.\\n\\nMoved by their plight, Kibo knew he had to help. With his powerful trunk, he dug deep into the ground, unearthing a hidden underground spring. Water gushed forth, quenching the villagers' thirst and bringing hope back to their lives.\\n\\nNews of Kibo's incredible act of kindness spread far and wide. People from distant lands came to witness the miracle elephant who had saved a village. Kibo became a symbol of hope and compassion, inspiring others to lend a helping hand to those in need.\\n\\nFrom that day forward, Kibo continued to use his strength and wisdom to assist others. He became a beloved figure, known as the Guardian of the Savannah. And whenever someone faced a challenge, they would look to the horizon, hoping to catch a glimpse of Kibo, the mighty elephant who taught the world the power of kindness.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chat_gpt import stream_store_response\n",
    "\n",
    "stream_store_response('write me a story of an elephant within 200 words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\gpt_engg\\GPT_Web_Personal\\trial.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gpt_engg/GPT_Web_Personal/trial.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m openai\u001b[39m.\u001b[39mapi_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msk-PTOFnx9e4JRRHFcfvYK2T3BlbkFJiZ9UsQyBjhTm3VX4xcfB\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gpt_engg/GPT_Web_Personal/trial.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m user_prompt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhi.. what is you name?\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/gpt_engg/GPT_Web_Personal/trial.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgpt-3.5-turbo-16k\u001b[39;49m\u001b[39m'\u001b[39;49m,messages\u001b[39m=\u001b[39;49m[{\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39myou\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mre a helpful assistant.\u001b[39;49m\u001b[39m\"\u001b[39;49m},{\u001b[39m'\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m: user_prompt}])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gpt_engg/GPT_Web_Personal/trial.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(response)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key=\"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\"\n",
    "\n",
    "user_prompt='hi.. what is you name?'\n",
    "response = openai.ChatCompletion.create(model='gpt-3.5-turbo-16k',messages=[{\"role\": \"system\", \"content\": \"you're a helpful assistant.\"},{'role': 'user', 'content': user_prompt}])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BingChat|DEBUG   |2023-09-10T23:30:16+0530|Importing cookies from: cookies.json\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\gpt_engg\\GPT_Web_Personal\\trial.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gpt_engg/GPT_Web_Personal/trial.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     q \u001b[39m=\u001b[39m Query(user_input, style\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mprecise\u001b[39m\u001b[39m\"\u001b[39m, cookie_files\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtemplates\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mcookies.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gpt_engg/GPT_Web_Personal/trial.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mstr\u001b[39m(q))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/gpt_engg/GPT_Web_Personal/trial.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m structured_response(\u001b[39m'\u001b[39;49m\u001b[39mhii\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32md:\\gpt_engg\\GPT_Web_Personal\\trial.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gpt_engg/GPT_Web_Personal/trial.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_response\u001b[39m(user_input):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/gpt_engg/GPT_Web_Personal/trial.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     q \u001b[39m=\u001b[39m Query(user_input, style\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mprecise\u001b[39;49m\u001b[39m\"\u001b[39;49m, cookie_files\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtemplates\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mcookies.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gpt_engg/GPT_Web_Personal/trial.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mstr\u001b[39m(q))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\EdgeGPT\\EdgeUtils.py:158\u001b[0m, in \u001b[0;36mQuery.__init__\u001b[1;34m(self, prompt, style, content_type, cookie_files, ignore_cookies, echo, echo_prompt, locale, simplify_response)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m content_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    157\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstyle \u001b[39m=\u001b[39m style\n\u001b[1;32m--> 158\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_and_send_query(echo, echo_prompt)\n\u001b[0;32m    159\u001b[0m \u001b[39mif\u001b[39;00m content_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_image()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\EdgeGPT\\EdgeUtils.py:163\u001b[0m, in \u001b[0;36mQuery.log_and_send_query\u001b[1;34m(self, echo, echo_prompt)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_and_send_query\u001b[39m(\u001b[39mself\u001b[39m, echo: \u001b[39mbool\u001b[39m, echo_prompt: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend_to_bing(echo, echo_prompt))\n\u001b[0;32m    164\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(Cookie, \u001b[39m\"\u001b[39m\u001b[39mcurrent_data\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    165\u001b[0m         name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<no_cookies>\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[39mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[39m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    189\u001b[0m \u001b[39mwith\u001b[39;00m Runner(debug\u001b[39m=\u001b[39mdebug) \u001b[39mas\u001b[39;00m runner:\n\u001b[0;32m    190\u001b[0m     \u001b[39mreturn\u001b[39;00m runner\u001b[39m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "from EdgeGPT.EdgeUtils import Query\n",
    "import re\n",
    "def structured_response(user_input):\n",
    "    q = Query(user_input, style=\"precise\", cookie_files=\"templates\\cookies.json\")\n",
    "    print(str(q))\n",
    "\n",
    "structured_response('hii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
